<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Lecture 1 - Linear Algebra & Calculus</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }
    nav { margin-bottom: 20px; }
    nav a { margin-right: 15px; text-decoration: none; color: #0073e6; }
    pre { background: #f4f4f4; padding: 10px; border-radius: 5px; }
  </style>
</head>
<body>
  <nav>
    <a href="Lecture1.html">Lecture 1</a>
    <a href="Lecture2.html">Lecture 2</a>
    <a href="Lecture3.html">Lecture 3</a>
  </nav>

  <h1>Lecture 1: Mathematical Foundations â€“ Linear Algebra & Calculus</h1>

  <h2>1. Vectors & Matrices</h2>
  <p>In Machine Learning, data is often represented as vectors and matrices. Example: 
  Each row of a dataset = one observation (feature vector).</p>

  <h3>Python Example: Vector Operations</h3>
  <pre><code class="language-python">
import numpy as np
# Feature vector: [age, income, score]
x = np.array([25, 50000, 0.85])
y = np.array([30, 60000, 0.9])

# Dot product (similarity measure)
dot = np.dot(x, y)
print("Dot Product:", dot)
  </code></pre>

  <h2>2. Calculus in ML</h2>
  <p>Calculus is used for optimization (training models). Gradient Descent applies derivatives to update parameters.</p>

  <h3>Example: Gradient Descent for Linear Regression</h3>
  <pre><code class="language-python">
import numpy as np

# Simple linear regression: y = mx + c
X = np.array([1, 2, 3, 4], dtype=float)
Y = np.array([2, 4, 6, 8], dtype=float)

m, c = 0.0, 0.0
lr = 0.01  # learning rate

for _ in range(1000):
    Y_pred = m*X + c
    error = Y - Y_pred
    m -= lr * (-2 * np.sum(X * error))
    c -= lr * (-2 * np.sum(error))

print("Learned slope:", m, "Intercept:", c)
  </code></pre>
</body>
</html>
