<!-- ========================= lecture_25.html ========================= -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Lecture 25 - Evaluation, Tuning, Deployment & Ethics</title>
  <style>
    :root{--bg:#f9fbff;--ink:#222;--brand:#003366;--accent:#0d6efd;--soft:#ffffff}
    body{font-family:Arial,Helvetica,sans-serif;margin:24px 5vw;background:var(--bg);color:var(--ink);line-height:1.6}
    .nav{display:flex;flex-wrap:wrap;gap:10px;margin:8px 0 24px}
    .nav a{padding:8px 12px;border-radius:8px;background:#fff;border:1px solid #e5e7eb;text-decoration:none;color:#0d6efd}
    .nav a[aria-current="page"]{background:#e7f1ff;border-color:#b6d4fe;color:#084298;font-weight:700}
    h1,h2,h3{color:var(--brand)}
    .card{background:#fff;border-radius:12px;padding:16px;margin:14px 0;box-shadow:0 2px 8px rgba(0,0,0,.06);border-left:5px solid var(--accent)}
    .grid{display:grid;gap:14px}
    @media(min-width:1000px){.grid.cols-2{grid-template-columns:1fr 1fr}.grid.cols-3{grid-template-columns:1fr 1fr 1fr}}
    code{background:#eef2f7;border-radius:4px;padding:2px 6px}
    .pro{color:#198754}.con{color:#dc3545}
    ul.tight>li{margin:4px 0}
  </style>
</head>
<body>
  <nav class="nav">
    <a href="https://surnamnarendra.github.io/Fundamentals-of-Machine-Learning/">Home</a>
    <a href="lecture_17.html">L21</a>
    <a href="lecture_18.html">L22</a>
    <a href="lecture_19.html">L23</a>
    <a href="lecture_20.html">L24</a>
    <a href="lecture_21.html" aria-current="page">L25</a>
    <a href="lecture_22.html">L26</a>
    <a href="lecture_23.html">L27</a>
    <a href="lecture_24.html">L28</a>
    <a href="lecture_25.html">L29</a>
    <a href="lecture_26.html">L30</a>
  </nav>

  <h1>Lecture 25: Evaluation, Tuning, Deployment & Ethics</h1>

  <h2>1) Model Evaluation</h2>
  <div class="grid cols-2">
    <div class="card">
      <b>Classification Metrics</b>
      <ul class="tight">
        <li>Accuracy, Precision, Recall, F1</li>
        <li>ROC-AUC, PR-AUC for imbalanced data</li>
        <li>Confusion Matrix for class-wise errors</li>
      </ul>
    </div>
    <div class="card">
      <b>Regression Metrics</b>
      <ul class="tight">
        <li>MSE, RMSE, MAE</li>
        <li>R² – proportion of variance explained</li>
        <li>MAPE for interpretability in % terms</li>
      </ul>
    </div>
  </div>

  <h2>2) Validation Techniques</h2>
  <div class="card">
    <ul class="tight">
      <li>Train/Validation/Test Split – holdout method</li>
      <li>k-Fold Cross-Validation – robust evaluation</li>
      <li>Stratified CV – preserve class proportions</li>
      <li>Time-Series CV – rolling or expanding windows</li>
    </ul>
  </div>

  <h2>3) Hyperparameter Tuning</h2>
  <div class="grid cols-3">
    <div class="card">
      <b>Grid Search</b>
      <ul class="tight"><li>Exhaustive search over combinations</li><li>Simple but expensive</li></ul>
    </div>
    <div class="card">
      <b>Random Search</b>
      <ul class="tight"><li>Samples random combinations</li><li>Faster, often effective</li></ul>
    </div>
    <div class="card">
      <b>Bayesian Optimization</b>
      <ul class="tight"><li>Models the objective function</li><li>Efficient with fewer trials</li></ul>
    </div>
  </div>

  <h2>4) Deployment</h2>
  <div class="grid cols-2">
    <div class="card">
      <b>Packaging</b>
      <ul class="tight">
        <li>Pickle/Joblib for model serialization</li>
        <li>Export to ONNX/TF-Lite for portability</li>
      </ul>
    </div>
    <div class="card">
      <b>Serving</b>
      <ul class="tight">
        <li>Flask/FastAPI endpoints</li>
        <li>Batch vs Real-time inference</li>
        <li>Monitor latency, throughput, errors</li>
      </ul>
    </div>
  </div>

  <h2>5) Monitoring in Production</h2>
  <div class="card">
    <ul class="tight">
      <li>Drift Detection – input distribution shift</li>
      <li>Performance Decay – evaluate with fresh labels</li>
      <li>Logging & Retraining pipelines</li>
    </ul>
  </div>

  <h2>6) Ethics in Machine Learning</h2>
  <div class="grid cols-2">
    <div class="card">
      <b>Bias & Fairness</b>
      <ul class="tight">
        <li>Bias from skewed data or features</li>
        <li>Fairness metrics: demographic parity, equal opportunity</li>
      </ul>
    </div>
    <div class="card">
      <b>Transparency & Interpretability</b>
      <ul class="tight">
        <li>SHAP, LIME for local explanations</li>
        <li>Feature importance plots</li>
      </ul>
    </div>
  </div>
  <div class="grid cols-2">
    <div class="card">
      <b>Privacy</b>
      <ul class="tight">
        <li>Differential privacy & federated learning</li>
        <li>Secure data handling & compliance (GDPR, HIPAA)</li>
      </ul>
    </div>
    <div class="card">
      <b>Accountability</b>
      <ul class="tight">
        <li>Human-in-the-loop decision systems</li>
        <li>Auditability & documentation (Model Cards, Datasheets)</li>
      </ul>
    </div>
  </div>

  <h2>7) Practical Workflow Example</h2>
  <div class="card">
    <pre><code># Hyperparameter tuning with CV (pseudocode)
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

param_grid = {"n_estimators": [100,200,500],
              "max_depth": [5,10,None],
              "min_samples_split": [2,5,10]}

rf = RandomForestClassifier(class_weight="balanced")
cv = GridSearchCV(rf, param_grid, cv=5, scoring="f1")
cv.fit(X_train, y_train)
print(cv.best_params_, cv.best_score_)</code></pre>
  </div>

  <h2>8) Exercise</h2>
  <div class="card">
    <b>Hands-on Challenge:</b> Tune hyperparameters for Logistic Regression, RandomForest, and XGBoost on the same dataset. Compare evaluation metrics (F1, ROC-AUC, PR-AUC). Deploy the best model as a FastAPI service and simulate drift by changing test distribution.
  </div>

</body>
</html>
